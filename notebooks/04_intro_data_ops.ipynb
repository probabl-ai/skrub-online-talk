{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb6a369",
   "metadata": {},
   "source": [
    "\n",
    "# Machine learning pipelines with multiple tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skrub\n",
    "\n",
    "dataset = skrub.datasets.fetch_credit_fraud(split=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9411d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "skrub.TableReport(dataset.baskets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a20a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "skrub.TableReport(dataset.products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f6c70",
   "metadata": {},
   "source": [
    "\n",
    "## The current state\n",
    "\n",
    "Let's ask an LLM to create a machine learning pipeline for the given dataset that is\n",
    "composed of two tables.\n",
    "\n",
    "**ðŸ¤– Prompt:**\n",
    "\n",
    "*I would like you to write a machine learning pipeline.\n",
    "\n",
    "The dataset is composed of two tables: `dataset.baskets` and `data.product`. The\n",
    "variable to predict is the column \"fraud_flag\" from the `data.baskets` table.\n",
    "\n",
    "So to create the a machine learning pipeline, you will need to kind of join the\n",
    "information between the two table and train and test a machine learning model for it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5869a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the tables to create features\n",
    "# First, let's aggregate product information by basket\n",
    "basket_features = (\n",
    "    dataset.products.groupby(\"basket_ID\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"cash_price\": [\"sum\", \"mean\", \"std\", \"min\", \"max\", \"count\"],\n",
    "            \"Nbr_of_prod_purchas\": [\"sum\", \"mean\", \"std\"],\n",
    "            \"item\": \"nunique\",  # Number of unique items\n",
    "            \"make\": \"nunique\",  # Number of unique makes\n",
    "            \"model\": \"nunique\",  # Number of unique models\n",
    "            \"goods_code\": \"nunique\",  # Number of unique goods codes\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Flatten column names\n",
    "basket_features.columns = [\"basket_ID\"] + [\n",
    "    f\"{col[0]}_{col[1]}\" for col in basket_features.columns[1:]\n",
    "]\n",
    "\n",
    "# Add additional features\n",
    "basket_features[\"avg_price_per_item\"] = (\n",
    "    basket_features[\"cash_price_sum\"] / basket_features[\"Nbr_of_prod_purchas_sum\"]\n",
    ")\n",
    "basket_features[\"price_std_norm\"] = basket_features[\"cash_price_std\"] / (\n",
    "    basket_features[\"cash_price_mean\"] + 1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "skrub.TableReport(basket_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a931c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with fraud labels\n",
    "df = dataset.baskets.merge(\n",
    "    basket_features, right_on=\"basket_ID\", left_on=\"ID\", how=\"left\"\n",
    ")\n",
    "skrub.TableReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a69a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features for fraud detection\n",
    "# These are domain-specific features that might be indicative of fraud\n",
    "\n",
    "# 1. Price anomaly features\n",
    "df[\"price_anomaly\"] = (\n",
    "    df[\"cash_price_sum\"] > df[\"cash_price_sum\"].quantile(0.95)\n",
    ").astype(int)\n",
    "df[\"low_price_anomaly\"] = (\n",
    "    df[\"cash_price_sum\"] < df[\"cash_price_sum\"].quantile(0.05)\n",
    ").astype(int)\n",
    "\n",
    "# 2. Quantity anomaly features\n",
    "df[\"quantity_anomaly\"] = (\n",
    "    df[\"Nbr_of_prod_purchas_sum\"] > df[\"Nbr_of_prod_purchas_sum\"].quantile(0.95)\n",
    ").astype(int)\n",
    "\n",
    "# 3. Diversity features\n",
    "df[\"item_diversity\"] = df[\"item_nunique\"] / (df[\"Nbr_of_prod_purchas_sum\"] + 1e-8)\n",
    "df[\"make_diversity\"] = df[\"make_nunique\"] / (df[\"Nbr_of_prod_purchas_sum\"] + 1e-8)\n",
    "\n",
    "# 4. Price consistency features\n",
    "df[\"price_consistency\"] = 1 / (\n",
    "    df[\"cash_price_std\"] + 1e-8\n",
    ")  # Higher values = more consistent prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "skrub.TableReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e828655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to be aligned with the next example\n",
    "id_split = 76543  # noqa\n",
    "df_train = df.query(\"ID <= @id_split\")\n",
    "df_test = df.query(\"ID > @id_split\")\n",
    "\n",
    "X_train = df_train.drop([\"basket_ID\", \"ID\", \"fraud_flag\"], axis=1)\n",
    "y_train = df_train[\"fraud_flag\"]\n",
    "X_test = df_test.drop([\"basket_ID\", \"ID\", \"fraud_flag\"], axis=1)\n",
    "y_test = df_test[\"fraud_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e97ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "X_train = X_train.fillna(0)  # Fill NaN with 0 for numerical features\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a57b00",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline using skrub's TableVectorizer\n",
    "preprocessor = skrub.TableVectorizer(\n",
    "    drop_if_constant=True,\n",
    "    high_cardinality=skrub.TextEncoder(),\n",
    "    low_cardinality=skrub.StringEncoder(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "# Train multiple models and compare performance\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    \"Gradient Boosting\": HistGradientBoostingClassifier(random_state=42, max_iter=100),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6738764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", model)])\n",
    "\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    results[name] = {\n",
    "        \"pipeline\": pipeline,\n",
    "        \"predictions\": y_pred,\n",
    "        \"probabilities\": y_pred_proba,\n",
    "        \"auc_score\": auc_score,\n",
    "    }\n",
    "\n",
    "    print(f\"{name} - AUC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f96c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate the best model (Random Forest typically performs well on tabular data)\n",
    "best_model_name = \"Random Forest\"\n",
    "best_pipeline = results[best_model_name][\"pipeline\"]\n",
    "y_pred = results[best_model_name][\"predictions\"]\n",
    "y_pred_proba = results[best_model_name][\"probabilities\"]\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"AUC Score: {results[best_model_name]['auc_score']:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675a097",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle(\"Fraud Detection Model Evaluation\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Confusion Matrix\")\n",
    "axes[0, 0].set_xlabel(\"Predicted\")\n",
    "axes[0, 0].set_ylabel(\"Actual\")\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "axes[0, 1].plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    linewidth=2,\n",
    "    label=f'ROC Curve (AUC = {results[best_model_name][\"auc_score\"]:.3f})',\n",
    ")\n",
    "axes[0, 1].plot([0, 1], [0, 1], \"k--\", linewidth=1)\n",
    "axes[0, 1].set_xlabel(\"False Positive Rate\")\n",
    "axes[0, 1].set_ylabel(\"True Positive Rate\")\n",
    "axes[0, 1].set_title(\"ROC Curve\")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Feature Importance (for Random Forest)\n",
    "if hasattr(best_pipeline.named_steps[\"classifier\"], \"feature_importances_\"):\n",
    "    feature_names = best_pipeline.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "    importances = best_pipeline.named_steps[\"classifier\"].feature_importances_\n",
    "\n",
    "    # Get top 10 most important features\n",
    "    top_indices = np.argsort(importances)[-10:]\n",
    "    top_features = [feature_names[i] for i in top_indices]\n",
    "    top_importances = importances[top_indices]\n",
    "\n",
    "    axes[1, 0].barh(range(len(top_features)), top_importances)\n",
    "    axes[1, 0].set_yticks(range(len(top_features)))\n",
    "    axes[1, 0].set_yticklabels(top_features)\n",
    "    axes[1, 0].set_xlabel(\"Feature Importance\")\n",
    "    axes[1, 0].set_title(\"Top 10 Most Important Features\")\n",
    "\n",
    "# 4. Model Comparison\n",
    "model_names = list(results.keys())\n",
    "auc_scores = [results[name][\"auc_score\"] for name in model_names]\n",
    "axes[1, 1].bar(model_names, auc_scores, color=[\"skyblue\", \"lightgreen\", \"lightcoral\"])\n",
    "axes[1, 1].set_ylabel(\"AUC Score\")\n",
    "axes[1, 1].set_title(\"Model Comparison\")\n",
    "axes[1, 1].tick_params(axis=\"x\", rotation=45)\n",
    "for i, v in enumerate(auc_scores):\n",
    "    axes[1, 1].text(i, v + 0.001, f\"{v:.3f}\", ha=\"center\", va=\"bottom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f896f88",
   "metadata": {},
   "source": [
    "\n",
    "**Pitfalls:**\n",
    "- Data leakage\n",
    "- Headache to replay the same code for a new batch of fresh data\n",
    "- Hard to tune hyperparameters related to the preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79524bd6",
   "metadata": {},
   "source": [
    "\n",
    "## The `skrub` Data Operations (DataOps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fabf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = skrub.datasets.fetch_credit_fraud(split=\"train\")\n",
    "baskets_experiment, products_experiment = dataset.baskets, dataset.products\n",
    "dataset = skrub.datasets.fetch_credit_fraud(split=\"test\")\n",
    "baskets_production, products_production = dataset.baskets, dataset.products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = skrub.var(\"products\")\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@skrub.deferred\n",
    "def aggregate_basket_features(products):\n",
    "    basket_features = (\n",
    "        products.groupby(\"basket_ID\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"cash_price\": [\"sum\", \"mean\", \"std\", \"min\", \"max\", \"count\"],\n",
    "                \"Nbr_of_prod_purchas\": [\"sum\", \"mean\", \"std\"],\n",
    "                \"item\": \"nunique\",  # Number of unique items\n",
    "                \"make\": \"nunique\",  # Number of unique makes\n",
    "                \"model\": \"nunique\",  # Number of unique models\n",
    "                \"goods_code\": \"nunique\",  # Number of unique goods codes\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Flatten column names\n",
    "    basket_features.columns = [\"basket_ID\"] + [\n",
    "        f\"{col[0]}_{col[1]}\" for col in basket_features.columns[1:]\n",
    "    ]\n",
    "\n",
    "    # Add additional features\n",
    "    basket_features[\"avg_price_per_item\"] = (\n",
    "        basket_features[\"cash_price_sum\"] / basket_features[\"Nbr_of_prod_purchas_sum\"]\n",
    "    )\n",
    "    basket_features[\"price_std_norm\"] = basket_features[\"cash_price_std\"] / (\n",
    "        basket_features[\"cash_price_mean\"] + 1e-8\n",
    "    )\n",
    "\n",
    "    return basket_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808234aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_features = aggregate_basket_features(products)\n",
    "basket_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aebd0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = skrub.var(\"products\", products_experiment)\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6719707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_features = aggregate_basket_features(products)\n",
    "basket_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc316f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets = skrub.var(\"baskets\", baskets_experiment)\n",
    "baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets = baskets.skb.subsample(n=5_000)\n",
    "baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = baskets[[\"ID\"]].skb.mark_as_X()\n",
    "target = baskets[\"fraud_flag\"].skb.mark_as_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f630c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b6d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@skrub.deferred\n",
    "def join_basket_aggregated_products(baskets, basket_features):\n",
    "    return baskets.merge(\n",
    "        basket_features, right_on=\"basket_ID\", left_on=\"ID\", how=\"left\"\n",
    "    ).drop(columns=[\"basket_ID\", \"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_features = join_basket_aggregated_products(features, basket_features)\n",
    "aggregated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52545e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@skrub.deferred\n",
    "def add_domain_specific_features(df):\n",
    "    # 1. Price anomaly features\n",
    "    df[\"price_anomaly\"] = (\n",
    "        df[\"cash_price_sum\"] > df[\"cash_price_sum\"].quantile(0.95)\n",
    "    ).astype(int)\n",
    "    df[\"low_price_anomaly\"] = (\n",
    "        df[\"cash_price_sum\"] < df[\"cash_price_sum\"].quantile(0.05)\n",
    "    ).astype(int)\n",
    "\n",
    "    # 2. Quantity anomaly features\n",
    "    df[\"quantity_anomaly\"] = (\n",
    "        df[\"Nbr_of_prod_purchas_sum\"] > df[\"Nbr_of_prod_purchas_sum\"].quantile(0.95)\n",
    "    ).astype(int)\n",
    "\n",
    "    # 3. Diversity features\n",
    "    df[\"item_diversity\"] = df[\"item_nunique\"] / (df[\"Nbr_of_prod_purchas_sum\"] + 1e-8)\n",
    "    df[\"make_diversity\"] = df[\"make_nunique\"] / (df[\"Nbr_of_prod_purchas_sum\"] + 1e-8)\n",
    "\n",
    "    # 4. Price consistency features\n",
    "    df[\"price_consistency\"] = 1 / (\n",
    "        df[\"cash_price_std\"] + 1e-8\n",
    "    )  # Higher values = more consistent prices\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd53880",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features = add_domain_specific_features(aggregated_features)\n",
    "engineered_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bdc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_model = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", HistGradientBoostingClassifier(random_state=42, max_iter=100)),\n",
    "    ]\n",
    ")\n",
    "predictions = engineered_features.skb.apply(predictive_model, y=target)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3921e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "predictions.skb.cross_validate(scoring=\"roc_auc\", cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f4418",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.skb.full_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57aa414",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = predictions.skb.make_learner(fitted=True)\n",
    "learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = learner.predict_proba(\n",
    "    {\"baskets\": baskets_experiment, \"products\": products_experiment}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b23953",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(baskets_experiment[\"fraud_flag\"], y_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eac335",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = learner.predict_proba(\n",
    "    {\"baskets\": baskets_production, \"products\": products_production}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13448096",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(baskets_production[\"fraud_flag\"], y_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223394b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
