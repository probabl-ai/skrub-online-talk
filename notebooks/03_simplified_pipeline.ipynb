{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "414f67b9",
   "metadata": {},
   "source": [
    "\n",
    "# Simplified machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skrub\n",
    "\n",
    "dataset = skrub.datasets.fetch_employee_salaries()\n",
    "report = skrub.TableReport(dataset.employee_salaries)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2582605",
   "metadata": {},
   "source": [
    "\n",
    "Let's ask an LLM to come a preprocessing pipeline given the complex dataset that we\n",
    "are facing.\n",
    "\n",
    "**ðŸ¤– Prompt:**\n",
    "\n",
    "*Given the type of data in the `dataset.X` dataframe, can you build a\n",
    "preprocessing pipeline that I can then used with scikit-learn pipeline and\n",
    "specifically plugging a linear model like the `Ridge` as a predictor.*\n",
    "\n",
    "*However, you don't need to create the full machine learning pipeline. Only\n",
    "the preprocessing stage.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9491ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Numerical features preprocessing\n",
    "numerical_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "# Categorical features preprocessing\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Text features preprocessing (if present)\n",
    "text_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"\")),\n",
    "        (\"tfidf\", TfidfVectorizer(max_features=1000, stop_words=\"english\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, make_column_selector(dtype_include=[np.number])),\n",
    "        (\n",
    "            \"cat\",\n",
    "            categorical_transformer,\n",
    "            make_column_selector(dtype_include=[\"object\", \"category\"]),\n",
    "        ),\n",
    "        (\"text\", text_transformer, make_column_selector(dtype_include=[\"object\"])),\n",
    "    ],\n",
    "    remainder=\"passthrough\",  # Keep any remaining columns\n",
    ")\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de6ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = skrub.TableVectorizer()\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit_transform(dataset.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a918c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = skrub.TableVectorizer(\n",
    "    drop_if_constant=True,\n",
    "    high_cardinality=skrub.TextEncoder()\n",
    ")\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "predictive_model = skrub.tabular_pipeline(Ridge())\n",
    "predictive_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset.X, dataset.y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37507d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_model.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "predictive_model = skrub.tabular_pipeline(RandomForestRegressor())\n",
    "predictive_model"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
